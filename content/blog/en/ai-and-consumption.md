---
title: "AI and Consumption: How our habits are being shaped"
description: "OpenAI’s announcement in December regarding its recent agreement with Walt Disney once again raises questions about the (irresponsible) use of these tools promoted by multiple centers of power."
url_img: "/images/blog/ai-and-consumption-cover.png"
date: "2026-01-14"
author: "Farox"
tags: ["AI", "Consumption", "Sustainable Development"]
tintasur: true
---

The use of generative artificial intelligence tools has already become part of our everyday lives. As a result, a series of alarms have been raised in recent times about how consumption structures are being reshaped -across information, healthcare, content, and beyond- how these new habits impact societies, and what tools we have to protect ourselves from some of the effects these technologies may have on daily life.

The agreement announced last month between Disney and OpenAI once again brings to the surface a set of questions about what is currently happening with the use of these tools, what kinds of consumption are being encouraged by large corporations, and what consequences all of this may have, not only for people, but also for AI systems themselves.

## OpenAI + Disney: Where (Some) Dreams Come True

A bit of context always helps. The agreement announced between OpenAI and Disney marks yet another step deeper into the territory of generative artificial intelligence. The company agreed to invest one billion dollars in the firm led by Sam Altman and signed a three-year licensing contract that will allow more than 200 characters from Disney, Marvel, Pixar, and Star Wars to be legally used by users in content generated through Sora and ChatGPT’s image-generation features. In addition to the intellectual property license, Disney will use OpenAI’s APIs to develop products, experiences, and internal tools, including an integration with Disney+, where some user-created content will be showcased.

Both companies presented the agreement as a commitment to a "responsible and creative" use of AI, with explicit promises to protect user safety and creators’ rights.

![OpenAI + Disney: where (some) dreams come true](/images/blog/ai-and-consumption-image1.webp)

However, when we talk about "responsibility" and "rights", questions quickly arise about how this type of agreement impacts not only franchise workers, but also users -who will contribute creativity and content to a corporation seemingly in exchange for nothing- and the environment, particularly when irresponsible consumption trends driven by entertainment purposes are promoted (and is it only entertainment?).

Not long ago, converting personal photos into characters inspired by Studio Ghibli’s visual style became a widespread trend -one amplified by Altman himself-. This phenomenon reignited debates around the copyright of images used to train generative AI models, as well as the carbon footprint and the enormous amount of resources required to produce content purely for "entertainment".

According to an article published by UNRIC (United Nations Regional Information Centre for Western Europe) in mid-2024, "global AI demand is expected to consume between 4.2 and 6.6 billion cubic meters of water by 2027, exceeding Denmark’s total annual water withdrawal of between 4.0 and 6.0 billion cubic meters".

And when we talk about resources, we are not referring only to water. The electricity consumption required by data centers to train and operate large AI models is also extremely significant.

This brings us to the next point, because this is not just about Disney or OpenAI. It is about how these decisions contribute to the use of powerful tools to flood the digital space with both professional and exploratory AI-generated content, consuming enormous resources in a global context of energy and climate crisis, fostering a permanent state of distrust regarding the truthfulness of what we consume, and even undermining the usefulness of these tools, or the platforms that host their outputs.

## AI Slop: When the End Justifies the Means

The phenomenon known as "AI slop" -generally understood as AI-generated junk- has been flooding social media for some time, causing a profound structural transformation in how we consume information.

This term refers to repetitive, exploratory visual or textual content, often low-quality, generated with artificial intelligence, through which users attempt to go viral and obtain some form of economic benefit, as seen in cases like the viral "Shrimp Jesus". While major companies such as Meta actively promote this type of content and reap enormous profits by driving traffic to their platforms, the credibility and usefulness of well-established digital institutions like Wikipedia or Pinterest are increasingly being questioned as the internet becomes saturated with low-quality articles and massive volumes of AI-generated material.

![Shrimp Jesus](/images/blog/ai-and-consumption-image2.jpeg)

Consider the environmental impact of thousands of users generating this type of content every hour in pursuit of virality and product sales; or the erosion of the concept of "objective reality" if we become accustomed to an environment where everything is false until proven otherwise; or even worse, how these patterns exacerbate the "liar’s dividend," allowing political actors to benefit from deception by dismissing incriminating truths as fake and spreading uncertainty through misinformation and false narratives.

Responsibility does not lie primarily with users. The challenge of building a healthier technological environment goes beyond misinformation and the promotion of harmful practices by political or economic actors. It requires the search for more sustainable alternatives -economically, ecologically, ethically, and socially- for the consumption, development, and training of these technologies.

## An Alliance That Suggests a Direction

The OpenAI–Walt Disney alliance is striking not only because it illustrates the uses being promoted for these tools, but also because the agreement describes Disney as "_the first major content licensing partner for Sora_". This raises important questions about the future envisioned for the entertainment industry under these policies and partnerships:

- Are users being conditioned to accept this type of content so that fully AI-generated animated films will not feel surprising in the future?
- Where do Disney’s animators, illustrators, and creative professionals fit into this process?
- What are the professional, social, and creative costs of such corporate strategies?
- Does the creativity of Sora and ChatGPT users -whose content may be featured on Disney+- represent a new form of unrecognized labor?
- As a society, what value are we assigning to creative processes?

The development of generative artificial intelligence has opened countless opportunities to address challenges that seemed impossible just a few years ago, from medicine to content creation. Research into the ethical use of these tools offers new perspectives that suggest the future could be one where technology genuinely serves societies and their real needs. To get there, we must continue debating, proposing ideas, and working to raise awareness and promote public and private policies that foster inclusive development, so that we can build a world where everyone’s dreams can come true, not just those of a few.

## Sources and Recommended Reading
- [OpenAI–Disney Agreement](https://openai.com/en-US/index/disney-sora-agreement/)
- [AI Energy Consumption](https://www.mdpi.com/2227-9709/11/3/58)
- [UNRIC on AI Energy Use](https://unric.org/en/artificial-intelligence-how-much-energy-does-ai-use/)
- [AI Slop Explained](https://theconversation.com/what-is-ai-slop-a-technologist-explains-this-new-and-largely-unwelcome-form-of-online-content-256554)